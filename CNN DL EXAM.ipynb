{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=(64,64,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 28,640\n",
      "Trainable params: 28,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.ImageDataGenerator at 0x19e74510948>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"YOUR FILE PATH\" is the local path of your machine where you have set up your folders for training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x19e744e5c08>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory (\n",
    "    'C:\\\\Users\\\\sowndariya\\\\Desktop\\\\dl\\\\DL Paper 1\\\\Dataset\\\\CNN\\\\Brand Classification\\\\train',\\\n",
    "    target_size=(64, 64),\\\n",
    "    batch_size=32,\\\n",
    "    class_mode='categorical')\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.DirectoryIterator at 0x19e744e5cc8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\sowndariya\\\\Desktop\\\\dl\\\\DL Paper 1\\\\Dataset\\\\CNN\\\\Brand Classification\\\\test',\\\n",
    "        target_size=(64, 64),\\\n",
    "        batch_size=32,\\\n",
    "        class_mode='categorical')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### steps_per_epoch = Total Number of images in the training set\n",
    "### validation_steps = Total number of Images in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/2000 [..............................] - ETA: 0s - loss: 0.7252 - accuracy: 0.3333WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      "   1/2000 [..............................] - 0s 23ms/step - loss: 0.7252 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19e744e9d48>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=1,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target size is 64x64 as out CNN inputs the image size as 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image=image.load_img('Bata67.jpg',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x19E725F7DC8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the image to  numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image=image.img_to_array(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input needs to be in 4 dimesnion. 4th Dim represents the batch size so add one more dimesion using the expand_dims function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image=np.expand_dims(new_image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the image and store it in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.predict(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bata': 0, 'clarks': 1, 'leecooper': 2}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Dog\n"
     ]
    }
   ],
   "source": [
    "result=model.predict(new_image)\n",
    "if result[0][0]==1:\n",
    "    predict=print('This is a Dog')\n",
    "else:\n",
    "    predict=print('This is a Cat')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
